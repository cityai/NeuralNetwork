{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 4)                 8         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "input_shape=(1,)\n",
    "model.add(Dense(4,activation=\"relu\", input_shape=input_shape))\n",
    "model.add(Dense(5,activation=\"relu\"))\n",
    "model.add(Dense(6,activation=\"relu\"))\n",
    "model.add(Dense(4,activation=\"relu\"))\n",
    "model.add(Dense(3,activation=\"relu\"))\n",
    "model.add(Dense(3,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "An experiemental drug was tested on individuals from ages 13 to 100.\n",
    "The trial had 2100 participants. Half were under 65 years old, half were over 65 years old.\n",
    "95% of patientes 65 or older experienced side effects.\n",
    "95% of patients under 65 experienced no side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y =  []\n",
    "train_x = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    # The 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_x.append(random_younger)\n",
    "    train_y.append(1)\n",
    "    \n",
    "    # The 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_x.append(random_older)\n",
    "    train_y.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    # The 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_x.append(random_younger)\n",
    "    train_y.append(0)\n",
    "    \n",
    "    # The 95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_x.append(random_older)\n",
    "    train_y.append(1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print\n",
    "train_y = np.array(train_y)\n",
    "train_x = np.array(train_x)\n",
    "#print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_x = scaler.fit_transform((train_x).reshape(-1,1))\n",
    "#print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\theano\\tensor\\subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 1.0735 - acc: 0.4937 - val_loss: 1.0712 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      " - 0s - loss: 1.0680 - acc: 0.5989 - val_loss: 1.0656 - val_acc: 0.6095\n",
      "Epoch 3/20\n",
      " - 2s - loss: 1.0625 - acc: 0.5132 - val_loss: 1.0600 - val_acc: 0.5429\n",
      "Epoch 4/20\n",
      " - 0s - loss: 1.0569 - acc: 0.5212 - val_loss: 1.0544 - val_acc: 0.5571\n",
      "Epoch 5/20\n",
      " - 1s - loss: 1.0514 - acc: 0.5323 - val_loss: 1.0486 - val_acc: 0.5667\n",
      "Epoch 6/20\n",
      " - 1s - loss: 1.0457 - acc: 0.5460 - val_loss: 1.0427 - val_acc: 0.5810\n",
      "Epoch 7/20\n",
      " - 0s - loss: 1.0400 - acc: 0.5561 - val_loss: 1.0366 - val_acc: 0.5905\n",
      "Epoch 8/20\n",
      " - 0s - loss: 1.0341 - acc: 0.5646 - val_loss: 1.0304 - val_acc: 0.6095\n",
      "Epoch 9/20\n",
      " - 0s - loss: 1.0282 - acc: 0.5720 - val_loss: 1.0240 - val_acc: 0.6095\n",
      "Epoch 10/20\n",
      " - 0s - loss: 1.0221 - acc: 0.5788 - val_loss: 1.0174 - val_acc: 0.6238\n",
      "Epoch 11/20\n",
      " - 0s - loss: 1.0158 - acc: 0.5878 - val_loss: 1.0105 - val_acc: 0.6333\n",
      "Epoch 12/20\n",
      " - 0s - loss: 1.0092 - acc: 0.6037 - val_loss: 1.0034 - val_acc: 0.6476\n",
      "Epoch 13/20\n",
      " - 0s - loss: 1.0024 - acc: 0.6243 - val_loss: 0.9961 - val_acc: 0.6524\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.9955 - acc: 0.6397 - val_loss: 0.9885 - val_acc: 0.6667\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.9884 - acc: 0.6545 - val_loss: 0.9805 - val_acc: 0.6905\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.9810 - acc: 0.6646 - val_loss: 0.9723 - val_acc: 0.7190\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.9733 - acc: 0.6788 - val_loss: 0.9635 - val_acc: 0.7286\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.9651 - acc: 0.6921 - val_loss: 0.9542 - val_acc: 0.7429\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.9563 - acc: 0.7132 - val_loss: 0.9444 - val_acc: 0.7762\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.9468 - acc: 0.7413 - val_loss: 0.9339 - val_acc: 0.8238\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "model.fit(scaled_train_x, train_y, validation_split=0.1, epochs=20, verbose=2)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.array([78,44,76,95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform((pred).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples) \n",
    "rounded_predictions = model.predict_classes(scaled_test_samples) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
